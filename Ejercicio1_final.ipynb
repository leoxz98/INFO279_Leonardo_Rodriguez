{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Cargar los datos\n",
    "df = pd.read_csv('train_data.csv')\n",
    "muestra_por_clase = 2000 #Toma una muestra x datos por cada clase para el entrenamiento\n",
    "df_muestra = df.groupby('clase', group_keys=False).apply(lambda x: x.sample(min(len(x), muestra_por_clase)))\n",
    "\n",
    "df_muestra.reset_index(drop=True, inplace=True) # Se guarda el dataset de la muestra tomada\n",
    "df_muestra.to_csv('muestra1.csv', index=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga del modelo y definición de la función de preprocesamiento\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm') \n",
    "\n",
    "def preprocess_text_spacy(text):\n",
    "    doc = nlp(text.lower())\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n",
    "    return ' '.join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamiento, se guardan los tokens resultantes en una columna para no estar preprocesado cada vez\n",
    "df = pd.read_csv('muestra1.csv')\n",
    "df['tokens'] = df['text'].apply(preprocess_text_spacy)\n",
    "df.to_csv('muestra1_tokens.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Index(['date', 'id_news', 'media_outlet', 'title', 'text', 'url', 'year',\n",
      "       'clase', 'tokens'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Eliminar filas con valores NaN en la columna 'tokens'\n",
    "df = pd.read_csv('muestra1_tokens.csv')\n",
    "df = df.dropna(subset=['tokens'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "# Vectorización\n",
    "vectorizer = CountVectorizer(max_features=5000)\n",
    "X_bow = vectorizer.fit_transform(df['tokens']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Division del dataset para entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bow, df['clase'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Random Forest: 0.6158578263841422\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     accidentes       0.67      0.75      0.71       344\n",
      "        ciencia       0.66      0.46      0.54       436\n",
      "       deportes       0.56      0.54      0.55       400\n",
      "       economia       0.57      0.66      0.61       415\n",
      "      educacion       0.58      0.53      0.56       406\n",
      "entretenimiento       0.55      0.53      0.54       397\n",
      "  internacional       0.69      0.85      0.76       396\n",
      " medio_ambiente       0.57      0.62      0.59       411\n",
      "       politica       0.68      0.67      0.68       403\n",
      "          salud       0.60      0.42      0.50       401\n",
      "     tecnologia       0.64      0.79      0.71       380\n",
      "\n",
      "       accuracy                           0.62      4389\n",
      "      macro avg       0.62      0.62      0.61      4389\n",
      "   weighted avg       0.61      0.62      0.61      4389\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Como contaba con las etiquetes usé un enfoque supervisado\n",
    "# Como los datos textuales suelen tener una alta dimensionalidad, ya que cada palabra se convierte en una característica.\n",
    "# random Forest maneja bien la alta dimensionalidad porque cada árbol trabaja solo con un subconjunto aleatorio \n",
    "# de las características.\n",
    "\n",
    "model_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model_rf.fit(X_train, y_train)\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy Random Forest: {accuracy_score(y_test, y_pred_rf)}\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Vect_Ej1_final.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "# Guardar el modelo en un archivo local para poder reutilizar\n",
    "joblib.dump(model_rf, 'Model_Ej1_final.pkl')\n",
    "joblib.dump(vectorizer, 'Vect_Ej1_final.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leonardo\\AppData\\Local\\Temp\\ipykernel_8468\\2762299510.py:22: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_news = df.groupby('clase', group_keys=False).apply(\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "nlp = spacy.load('en_core_web_sm') \n",
    "\n",
    "def preprocess_text_spacy(text):\n",
    "    doc = nlp(text.lower())\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Carga el modelo y el vectorizador\n",
    "modelo = joblib.load('Model_Ej1_final.pkl') #Entrenamiento con 20k de datos -> 40min\n",
    "vectorizador = joblib.load('Vect_Ej1_final.pkl')\n",
    "\n",
    "# Carga el dataset\n",
    "df = pd.read_csv('train_data.csv') # remplazar datos para probar\n",
    "\n",
    "# En caso de tener datos no etiquedatos con \"clase\" comentar esto ->\n",
    "muestra_por_clase = 5  # Ajustar este número según sea necesario\n",
    "df_news = df.groupby('clase', group_keys=False).apply(\n",
    "    lambda x: x.sample(min(len(x), muestra_por_clase), random_state=70).sample(frac=1, random_state=70)  \n",
    ")\n",
    "\n",
    "# hasta aqui y descomentar lo siguiente\n",
    "#df_news = df.sample(n=10, random_state=70)\n",
    "\n",
    "# Preprocesa los textos\n",
    "df_news[\"tokens\"] = df_news['text'].apply(preprocess_text_spacy)\n",
    "\n",
    "# Transforma los textos con el vectorizador\n",
    "X_transformed = vectorizador.transform(df_news[\"tokens\"])\n",
    "\n",
    "# Realiza la predicción con el modelo\n",
    "df_news[\"val_predict\"] = modelo.predict(X_transformed)\n",
    "\n",
    "#print(df_news.head())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     accidentes       0.83      1.00      0.91         5\n",
      "        ciencia       1.00      1.00      1.00         5\n",
      "       deportes       0.75      0.60      0.67         5\n",
      "       economia       0.60      0.60      0.60         5\n",
      "      educacion       1.00      0.80      0.89         5\n",
      "entretenimiento       0.80      0.80      0.80         5\n",
      "  internacional       1.00      1.00      1.00         5\n",
      " medio_ambiente       1.00      1.00      1.00         5\n",
      "       politica       1.00      1.00      1.00         5\n",
      "          salud       0.83      1.00      0.91         5\n",
      "     tecnologia       1.00      1.00      1.00         5\n",
      "\n",
      "       accuracy                           0.89        55\n",
      "      macro avg       0.89      0.89      0.89        55\n",
      "   weighted avg       0.89      0.89      0.89        55\n",
      "\n",
      "\n",
      " Predicciones acertadas:  49 de 55, aprox un 0.89% \n",
      "\n",
      "              clase      val_predict\n",
      "0        accidentes       accidentes\n",
      "1        accidentes       accidentes\n",
      "2        accidentes       accidentes\n",
      "3        accidentes       accidentes\n",
      "4        accidentes       accidentes\n",
      "5           ciencia          ciencia\n",
      "6           ciencia          ciencia\n",
      "7           ciencia          ciencia\n",
      "8           ciencia          ciencia\n",
      "9           ciencia          ciencia\n",
      "10         deportes         deportes\n",
      "11         deportes         deportes\n",
      "12         deportes         economia\n",
      "13         deportes         deportes\n",
      "14         deportes  entretenimiento\n",
      "15         economia         economia\n",
      "16         economia         deportes\n",
      "17         economia         economia\n",
      "18         economia       accidentes\n",
      "19         economia         economia\n",
      "20        educacion            salud\n",
      "21        educacion        educacion\n",
      "22        educacion        educacion\n",
      "23        educacion        educacion\n",
      "24        educacion        educacion\n",
      "25  entretenimiento  entretenimiento\n",
      "26  entretenimiento  entretenimiento\n",
      "27  entretenimiento  entretenimiento\n",
      "28  entretenimiento  entretenimiento\n",
      "29  entretenimiento         economia\n",
      "30    internacional    internacional\n",
      "31    internacional    internacional\n",
      "32    internacional    internacional\n",
      "33    internacional    internacional\n",
      "34    internacional    internacional\n",
      "35   medio_ambiente   medio_ambiente\n",
      "36   medio_ambiente   medio_ambiente\n",
      "37   medio_ambiente   medio_ambiente\n",
      "38   medio_ambiente   medio_ambiente\n",
      "39   medio_ambiente   medio_ambiente\n",
      "40         politica         politica\n",
      "41         politica         politica\n",
      "42         politica         politica\n",
      "43         politica         politica\n",
      "44         politica         politica\n",
      "45            salud            salud\n",
      "46            salud            salud\n",
      "47            salud            salud\n",
      "48            salud            salud\n",
      "49            salud            salud\n",
      "50       tecnologia       tecnologia\n",
      "51       tecnologia       tecnologia\n",
      "52       tecnologia       tecnologia\n",
      "53       tecnologia       tecnologia\n",
      "54       tecnologia       tecnologia\n"
     ]
    }
   ],
   "source": [
    "# Verificar resultados manualmente\n",
    "# Comentar si no hay datos etiquetados\n",
    "y_true = df_news[\"clase\"]  # Etiquetas verdaderas\n",
    "y_pred = df_news[\"val_predict\"]  # Predicciones hechas por el modelo\n",
    "\n",
    "# Imprimir el classification report\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "filas_iguales = (df_news['clase'] == df_news['val_predict']).sum()\n",
    "total_filas = df_news.shape[0]\n",
    "print(f\"\\n Predicciones acertadas:  {filas_iguales} de {total_filas}, aprox un {(filas_iguales/total_filas):.2f}% \\n\")\n",
    "print(df_news[['clase', 'val_predict']])\n",
    "df_news.reset_index(drop=True, inplace=True)\n",
    "df_news.to_csv('ej1_resultados.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
