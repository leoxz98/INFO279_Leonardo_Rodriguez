{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leonardo\\AppData\\Local\\Temp\\ipykernel_4148\\865782627.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_muestra = df.groupby('clase', group_keys=False).apply(lambda x: x.sample(min(len(x), muestra_por_clase)))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# resultado se guarda en muestra2.csv\n",
    "# Cargar los datos\n",
    "df = pd.read_csv('train_data.csv')\n",
    "\n",
    "muestra_por_clase = 10\n",
    "# Si hay datos etiquetados usar este, si no descomentar el siguiente\n",
    "df_muestra = df.groupby('clase', group_keys=False).apply(lambda x: x.sample(min(len(x), muestra_por_clase)))\n",
    "#df_muestra = df.sample(n=10, random_state=70)\n",
    "\n",
    "\n",
    "# Crear columnas nuevas para el dataset\n",
    "df_muestra[\"event\"] = \"\"\n",
    "df_muestra[\"aux1\"] = \"\"\n",
    "df_muestra[\"category\"] = \"\"\n",
    "df_muestra[\"address\"] = \"\"\n",
    "df_muestra[\"latitud\"] = \"\"\n",
    "df_muestra[\"longitud\"] = \"\"\n",
    "\n",
    "df_muestra.reset_index(drop=True, inplace=True)\n",
    "df_muestra.to_csv('muestra2.csv', index=False)\n",
    "\n",
    "#print(df_muestra.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leonardo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline\n",
    "\n",
    "# Cargar el modelo de QA\n",
    "qa_model = pipeline(\"question-answering\", model=\"timpal0l/mdeberta-v3-base-squad2\")\n",
    "# Cargar el modelo de spaCy\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "def identificar_evento_principal(texto):\n",
    "    respuesta = qa_model(question=\"¿Cuál es el evento principal?\", context=texto)\n",
    "    return respuesta['answer']\n",
    "\n",
    "def extraer_tres_primeras_frases(texto):\n",
    "    # Tomar una parte de texto para obtener el evento principal sin mucha carga de procesamiento\n",
    "    frases = texto.split('.')[:5]  # Cambiar a 5\n",
    "    text = \". \".join(frase.strip() for frase in frases if frase.strip())  \n",
    "    if text:  \n",
    "        text += '.'  \n",
    "    return text\n",
    "\n",
    "# Obtener evento y guardar\n",
    "df_muestra[\"aux1\"] = df_muestra[\"text\"].apply(extraer_tres_primeras_frases)  \n",
    "df_muestra[\"event\"] = df_muestra[\"aux1\"].apply(identificar_evento_principal)  \n",
    "\n",
    "df_muestra.reset_index(drop=True, inplace=True)\n",
    "df_muestra.to_csv('muestra2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import joblib\n",
    "\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "# Prepocesamiento\n",
    "def preprocess_text_spacy(text):\n",
    "    doc = nlp(text.lower())\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Reutilizar los modelos del ejericico 1 para sacar la categoria de la notica\n",
    "modelo = joblib.load('Model_Ej1_final.pkl') #Entrenamiento con 20k de datos -> 40min\n",
    "vectorizador = joblib.load('Vect_Ej1_final.pkl')\n",
    "\n",
    "df_muestra[\"tokens\"] = df_muestra['text'].apply(preprocess_text_spacy) # aplicar preprocesamiento\n",
    "X_transformed = vectorizador.transform(df_muestra[\"tokens\"])\n",
    "\n",
    "df_muestra[\"category\"] = modelo.predict(X_transformed) # realizar predicción y guardar\n",
    "\n",
    "df_muestra.reset_index(drop=True, inplace=True)\n",
    "df_muestra.to_csv('muestra2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.exc import GeocoderTimedOut\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"Sophia\")\n",
    "\n",
    "def get_addres(text): # Usar el modelo para obtener la ubicación\n",
    "    question = \"En qué lugar fisico ocurre exactamente el evento?\"\n",
    "    context = text\n",
    "    resp = qa_model(question = question, context = context)\n",
    "    return resp['answer']\n",
    "\n",
    "def extraer_loc_con_spacy(texto): # extraer entidades de localización \n",
    "    doc = nlp(texto)\n",
    "    locaciones = [ent.text for ent in doc.ents if ent.label_ == \"LOC\"]\n",
    "    return \", \".join(locaciones) if locaciones else None\n",
    "\n",
    "def obtener_coordenadas(direccion): # Localizar con geopy\n",
    "    if direccion:\n",
    "        try:\n",
    "            location = geolocator.geocode(direccion)\n",
    "            if location:\n",
    "                return location.latitude, location.longitude\n",
    "            else:\n",
    "                return None, None  \n",
    "        except GeocoderTimedOut:\n",
    "            return None, None\n",
    "    else:\n",
    "        return None, None  \n",
    "\n",
    "# Encadenar las 3 funciones usando una columna auxiliar e intentar localizar, si no se retorna none\n",
    "df_muestra[\"aux2\"] = df_muestra[\"text\"].apply(extraer_loc_con_spacy)\n",
    "df_muestra[\"address\"] = df_muestra[\"aux2\"].apply(lambda x: get_addres(x) if x else None)\n",
    "df_muestra[\"latitud\"], df_muestra[\"longitud\"] = zip(*df_muestra[\"address\"].apply(lambda x: obtener_coordenadas(x) if x else (None, None)))\n",
    "\n",
    "# guardar los datos\n",
    "df_muestra.reset_index(drop=True, inplace=True)\n",
    "df_muestra.to_csv('muestra2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar algunas columnas \n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "df = pd.read_csv('muestra2.csv')\n",
    "\n",
    "# Eliminar las columnas no deseadas (ejemplo: 'columna1' y 'columna2')\n",
    "df = df.drop(['date','media_outlet', 'title','url','text','year','clase','aux1','aux2','tokens'], axis=1)\n",
    "\n",
    "\n",
    "# Guardar los cambios en un nuevo archivo CSV\n",
    "df.to_csv('muestra2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
